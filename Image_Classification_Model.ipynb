{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":71280,"databundleVersionId":7787990,"sourceType":"competition"}],"dockerImageVersionId":30647,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndirectory = '/kaggle/input/abdous-egg-experiment/dataset/dataset/day_'\ntarget_size = (224, 224)\n\n# initialize lists to store images and labels\nimages = []\nlabels = []\n\n# iterate over each file in the directory\nfor i in range(4):\n    for filename in os.listdir(directory+str(i+1)):\n        if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg') :\n            # load and preprocess the image\n            img = tf.keras.preprocessing.image.load_img(os.path.join(directory+str(i+1), filename), target_size=target_size)\n            img_array = tf.keras.preprocessing.image.img_to_array(img)\n            img_array =  preprocess_input(img_array)\n        \n            # add the preprocessed image to the list of images\n            images.append(img_array)\n            labels.append(i)\n\n# convert lists to numpy arrays\nX_train = np.array(images)\nY_train = np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T03:57:38.599708Z","iopub.execute_input":"2024-02-25T03:57:38.600084Z","iopub.status.idle":"2024-02-25T03:58:04.781848Z","shell.execute_reply.started":"2024-02-25T03:57:38.600053Z","shell.execute_reply":"2024-02-25T03:58:04.780993Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"np.unique(Y_train)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T03:58:04.783413Z","iopub.execute_input":"2024-02-25T03:58:04.783713Z","iopub.status.idle":"2024-02-25T03:58:04.790171Z","shell.execute_reply.started":"2024-02-25T03:58:04.783688Z","shell.execute_reply":"2024-02-25T03:58:04.789321Z"},"trusted":true},"execution_count":95,"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"array([0, 1, 2, 3])"},"metadata":{}}]},{"cell_type":"code","source":"X = all_images_array\nY = class_labels_array\nY = Y - 1","metadata":{"execution":{"iopub.status.busy":"2024-02-25T03:06:20.412874Z","iopub.execute_input":"2024-02-25T03:06:20.413645Z","iopub.status.idle":"2024-02-25T03:06:20.417801Z","shell.execute_reply.started":"2024-02-25T03:06:20.413612Z","shell.execute_reply":"2024-02-25T03:06:20.416792Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import EfficientNetB0\nimport tensorflow as tf\n\n\n# Load the pre-trained ResNet50 model without the top (fully connected) layers\neffnetb0 = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n# Freeze the weights of the pre-trained layers so they're not updated during training\nfor layer in effnetb0.layers:\n    layer.trainable = False\n\n# Create a new model on top of ResNet50\nmodel = Sequential([\n    effnetb0,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    Dense(1280, activation='relu'),\n    Dense(4, activation='softmax')  # 4 classes, so the output layer has 4 units with softmax activation\n])\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.001),\n              loss='sparse_categorical_crossentropy',  # Since class labels are integers\n              metrics=['accuracy'])\n\n# Print model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-25T03:59:42.745374Z","iopub.execute_input":"2024-02-25T03:59:42.746305Z","iopub.status.idle":"2024-02-25T03:59:45.529633Z","shell.execute_reply.started":"2024-02-25T03:59:42.746259Z","shell.execute_reply":"2024-02-25T03:59:45.528618Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"Model: \"sequential_6\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n efficientnetb0 (Functional  (None, 7, 7, 1280)        4049571   \n )                                                               \n                                                                 \n global_average_pooling2d_2  (None, 1280)              0         \n  (GlobalAveragePooling2D)                                       \n                                                                 \n dense_12 (Dense)            (None, 1280)              1639680   \n                                                                 \n dense_13 (Dense)            (None, 4)                 5124      \n                                                                 \n=================================================================\nTotal params: 5694375 (21.72 MB)\nTrainable params: 1644804 (6.27 MB)\nNon-trainable params: 4049571 (15.45 MB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(X_train,Y_train,batch_size=32,epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T03:59:51.752560Z","iopub.execute_input":"2024-02-25T03:59:51.753412Z","iopub.status.idle":"2024-02-25T04:01:17.192660Z","shell.execute_reply.started":"2024-02-25T03:59:51.753379Z","shell.execute_reply":"2024-02-25T04:01:17.191415Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2024-02-25 04:00:03.758825: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_6/efficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"119/119 [==============================] - 15s 62ms/step - loss: 0.5179 - accuracy: 0.8049\nEpoch 2/10\n119/119 [==============================] - 7s 61ms/step - loss: 0.3306 - accuracy: 0.8768\nEpoch 3/10\n119/119 [==============================] - 7s 61ms/step - loss: 0.3009 - accuracy: 0.8910\nEpoch 4/10\n119/119 [==============================] - 7s 61ms/step - loss: 0.2474 - accuracy: 0.9105\nEpoch 5/10\n119/119 [==============================] - 7s 61ms/step - loss: 0.2190 - accuracy: 0.9181\nEpoch 6/10\n119/119 [==============================] - 7s 61ms/step - loss: 0.2013 - accuracy: 0.9192\nEpoch 7/10\n119/119 [==============================] - 7s 60ms/step - loss: 0.1915 - accuracy: 0.9281\nEpoch 8/10\n119/119 [==============================] - 7s 61ms/step - loss: 0.2015 - accuracy: 0.9231\nEpoch 9/10\n119/119 [==============================] - 7s 60ms/step - loss: 0.1546 - accuracy: 0.9368\nEpoch 10/10\n119/119 [==============================] - 7s 61ms/step - loss: 0.1536 - accuracy: 0.9439\n","output_type":"stream"},{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7d78d007dc90>"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\n\n# Path to the main folder containing subfolders\nmain_folder = '/kaggle/input/abdous-egg-experiment/dataset/test'\n\n# List to store image arrays\nimage_arrays = []\nnames = []\n\n# Define a target size for resizing\ntarget_size = (224, 224)  # Adjust as needed\nfiles =os.listdir(main_folder)\nfiles.sort()\n# Iterate through subfolders\nfor image_file in files:\n    img = tf.keras.preprocessing.image.load_img(os.path.join(main_folder, image_file), target_size=target_size)\n    img_array = tf.keras.preprocessing.image.img_to_array(img)\n    img_array = preprocess_input(img_array)\n    names.append(image_file)\n    image_arrays.append(img_array)\n                \nprint(\"Shape of the final image array:\", len(image_arrays))\nprint(\"Shape of the final names array:\", len(names))","metadata":{"execution":{"iopub.status.busy":"2024-02-25T04:01:57.221468Z","iopub.execute_input":"2024-02-25T04:01:57.221835Z","iopub.status.idle":"2024-02-25T04:02:00.413338Z","shell.execute_reply.started":"2024-02-25T04:01:57.221808Z","shell.execute_reply":"2024-02-25T04:02:00.412388Z"},"trusted":true},"execution_count":107,"outputs":[{"name":"stdout","text":"Shape of the final image array: 419\nShape of the final names array: 419\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = model.predict(np.array(image_arrays))","metadata":{"execution":{"iopub.status.busy":"2024-02-25T04:02:00.415175Z","iopub.execute_input":"2024-02-25T04:02:00.415551Z","iopub.status.idle":"2024-02-25T04:02:01.558538Z","shell.execute_reply.started":"2024-02-25T04:02:00.415517Z","shell.execute_reply":"2024-02-25T04:02:01.557810Z"},"trusted":true},"execution_count":108,"outputs":[{"name":"stdout","text":"14/14 [==============================] - 1s 59ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"predictionsf = np.argmax(predictions , axis=1) + 1\npredictionsf","metadata":{"execution":{"iopub.status.busy":"2024-02-25T04:02:02.870508Z","iopub.execute_input":"2024-02-25T04:02:02.870919Z","iopub.status.idle":"2024-02-25T04:02:02.878590Z","shell.execute_reply.started":"2024-02-25T04:02:02.870887Z","shell.execute_reply":"2024-02-25T04:02:02.877642Z"},"trusted":true},"execution_count":109,"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"array([3, 1, 4, 4, 2, 1, 1, 3, 3, 4, 3, 1, 2, 3, 1, 4, 2, 3, 2, 3, 4, 1,\n       4, 1, 4, 4, 2, 4, 1, 2, 3, 4, 2, 4, 3, 3, 1, 3, 3, 4, 1, 2, 2, 3,\n       3, 4, 4, 2, 2, 1, 3, 3, 3, 1, 3, 4, 1, 3, 3, 4, 3, 4, 2, 3, 1, 1,\n       4, 2, 3, 1, 3, 2, 4, 1, 4, 3, 2, 1, 3, 1, 1, 4, 1, 3, 1, 3, 2, 4,\n       2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 4, 2, 4, 2, 4, 3, 2, 1, 1, 2, 4,\n       3, 2, 2, 2, 4, 2, 1, 2, 2, 2, 2, 3, 4, 4, 1, 4, 2, 2, 4, 1, 4, 2,\n       3, 2, 2, 4, 1, 4, 3, 2, 4, 3, 4, 2, 3, 1, 4, 1, 2, 4, 1, 2, 4, 3,\n       3, 3, 3, 3, 1, 3, 2, 2, 1, 3, 1, 2, 2, 1, 4, 2, 1, 2, 3, 3, 3, 1,\n       3, 1, 1, 3, 1, 4, 4, 3, 4, 4, 4, 3, 2, 4, 3, 4, 2, 1, 2, 3, 2, 2,\n       2, 2, 2, 3, 4, 2, 4, 2, 4, 4, 1, 2, 2, 1, 3, 2, 2, 2, 3, 1, 1, 3,\n       2, 4, 2, 4, 4, 2, 2, 1, 1, 1, 4, 2, 3, 3, 2, 2, 4, 4, 1, 2, 3, 4,\n       4, 1, 1, 2, 3, 2, 4, 2, 4, 1, 4, 2, 1, 2, 1, 1, 2, 4, 2, 2, 4, 4,\n       3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 4, 1, 1, 2, 4, 1, 1, 4, 4, 1, 1, 2,\n       3, 3, 3, 1, 2, 4, 1, 1, 4, 4, 3, 4, 3, 1, 2, 2, 4, 1, 1, 1, 4, 3,\n       1, 2, 4, 3, 1, 1, 4, 4, 2, 3, 3, 4, 1, 2, 2, 2, 4, 3, 4, 4, 1, 3,\n       3, 2, 3, 1, 2, 1, 1, 2, 2, 1, 1, 1, 4, 3, 1, 4, 4, 2, 4, 2, 2, 3,\n       3, 4, 2, 3, 2, 4, 4, 3, 2, 2, 1, 4, 4, 3, 1, 4, 4, 4, 1, 1, 4, 3,\n       3, 1, 1, 2, 3, 2, 4, 1, 3, 3, 3, 1, 2, 1, 2, 1, 1, 3, 2, 4, 4, 2,\n       1, 1, 2, 3, 3, 1, 1, 2, 1, 1, 2, 4, 2, 3, 1, 4, 1, 4, 3, 3, 1, 1,\n       4])"},"metadata":{}}]},{"cell_type":"code","source":"predictions_df = pd.DataFrame({'ID' : np.array(names), 'Target': predictionsf})\npredictions_df","metadata":{"execution":{"iopub.status.busy":"2024-02-25T04:02:08.387895Z","iopub.execute_input":"2024-02-25T04:02:08.388284Z","iopub.status.idle":"2024-02-25T04:02:08.400498Z","shell.execute_reply.started":"2024-02-25T04:02:08.388252Z","shell.execute_reply":"2024-02-25T04:02:08.399567Z"},"trusted":true},"execution_count":110,"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"                                           ID  Target\n0    00245649-f928-4878-9348-72a3e3a491ce.jpg       3\n1    00f07b6d-cf27-4c8e-a91a-4c6a70f67139.jpg       1\n2    021fdcac-1c0d-4162-a702-38ce19dda747.jpg       4\n3    02b17e8f-67b5-408e-80f9-68312c218bda.jpg       4\n4    02d23e88-9e5b-49b8-9253-b6bf5d5701ca.jpg       2\n..                                        ...     ...\n414  fdc9c6c8-f60c-4691-b120-6fe5a342a8ec.jpg       3\n415  fdfabeda-d78d-4c6f-bdce-00ee4c70972f.jpg       3\n416  fe35d9c4-10c5-4053-b326-a0eb7c6e60d9.jpg       1\n417  ff9259b3-cf45-4dfc-bdd6-13e0b1df9abb.jpg       1\n418  ffeaee54-fa38-416f-bf6d-28aab61ab050.jpg       4\n\n[419 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00245649-f928-4878-9348-72a3e3a491ce.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00f07b6d-cf27-4c8e-a91a-4c6a70f67139.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>021fdcac-1c0d-4162-a702-38ce19dda747.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>02b17e8f-67b5-408e-80f9-68312c218bda.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>02d23e88-9e5b-49b8-9253-b6bf5d5701ca.jpg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>fdc9c6c8-f60c-4691-b120-6fe5a342a8ec.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>415</th>\n      <td>fdfabeda-d78d-4c6f-bdce-00ee4c70972f.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>fe35d9c4-10c5-4053-b326-a0eb7c6e60d9.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>417</th>\n      <td>ff9259b3-cf45-4dfc-bdd6-13e0b1df9abb.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>418</th>\n      <td>ffeaee54-fa38-416f-bf6d-28aab61ab050.jpg</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>419 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictions_df.to_csv('pb3v2.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T04:02:13.063881Z","iopub.execute_input":"2024-02-25T04:02:13.064529Z","iopub.status.idle":"2024-02-25T04:02:13.071465Z","shell.execute_reply.started":"2024-02-25T04:02:13.064493Z","shell.execute_reply":"2024-02-25T04:02:13.070428Z"},"trusted":true},"execution_count":111,"outputs":[]}]}